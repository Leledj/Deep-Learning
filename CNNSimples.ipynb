{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 150, 150\n",
    "\n",
    "train_data_dir = 'dataset/TDdataset/train/'\n",
    "validation_data_dir = 'dataset/TDdataset/val/'\n",
    "test_data_dir = 'dataset/TDdataset/test/'\n",
    "nb_train_samples = 2000\n",
    "nb_validation_samples = 800\n",
    "epochs = 100\n",
    "batch_size = 16\n",
    "initial_learning_rate = 0.1\n",
    "\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "#     initial_learning_rate, decay_steps=100000, decay_rate=0.96, staircase=True\n",
    "# )\n",
    "\n",
    "opt = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "\n",
    "callback = keras.callbacks.EarlyStopping(monitor='loss', patience=5 ,mode='auto', verbose=1, min_delta=0.0001)\n",
    "\n",
    "# callback = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "#     monitor='loss',\n",
    "#     factor=0.1,\n",
    "#     patience=10,\n",
    "#     verbose=0,\n",
    "#     mode='auto',\n",
    "#     min_delta=0.0001,\n",
    "#     cooldown=0,\n",
    "#     min_lr=0.0000001,\n",
    "# )\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy', f1_m,precision_m, recall_m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2688 images belonging to 2 classes.\n",
      "Found 160 images belonging to 2 classes.\n",
      "Found 160 images belonging to 2 classes.\n",
      "Epoch 1/100\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.6873 - accuracy: 0.5580 - f1_m: 0.5021 - precision_m: 0.5753 - recall_m: 0.5278WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "125/125 [==============================] - 21s 158ms/step - loss: 0.6873 - accuracy: 0.5580 - f1_m: 0.5021 - precision_m: 0.5753 - recall_m: 0.5278 - val_loss: 0.6521 - val_accuracy: 0.5688 - val_f1_m: 0.4631 - val_precision_m: 0.5938 - val_recall_m: 0.3933\n",
      "Epoch 2/100\n",
      "125/125 [==============================] - 20s 158ms/step - loss: 0.6533 - accuracy: 0.5915 - f1_m: 0.4910 - precision_m: 0.6741 - recall_m: 0.4222\n",
      "Epoch 3/100\n",
      "125/125 [==============================] - 19s 148ms/step - loss: 0.6287 - accuracy: 0.6255 - f1_m: 0.4740 - precision_m: 0.7012 - recall_m: 0.3879\n",
      "Epoch 4/100\n",
      "125/125 [==============================] - 18s 147ms/step - loss: 0.6070 - accuracy: 0.6430 - f1_m: 0.4879 - precision_m: 0.7642 - recall_m: 0.3886\n",
      "Epoch 5/100\n",
      "125/125 [==============================] - 19s 151ms/step - loss: 0.5998 - accuracy: 0.6275 - f1_m: 0.4721 - precision_m: 0.7443 - recall_m: 0.3758\n",
      "Epoch 6/100\n",
      "125/125 [==============================] - 18s 147ms/step - loss: 0.5874 - accuracy: 0.6565 - f1_m: 0.5142 - precision_m: 0.7938 - recall_m: 0.4091\n",
      "Epoch 7/100\n",
      "125/125 [==============================] - 19s 148ms/step - loss: 0.5753 - accuracy: 0.6715 - f1_m: 0.5709 - precision_m: 0.7790 - recall_m: 0.4867\n",
      "Epoch 8/100\n",
      "125/125 [==============================] - 19s 149ms/step - loss: 0.5714 - accuracy: 0.6550 - f1_m: 0.5294 - precision_m: 0.7641 - recall_m: 0.4300\n",
      "Epoch 9/100\n",
      "125/125 [==============================] - 19s 155ms/step - loss: 0.5484 - accuracy: 0.6860 - f1_m: 0.5977 - precision_m: 0.7885 - recall_m: 0.5135\n",
      "Epoch 10/100\n",
      "125/125 [==============================] - 23s 182ms/step - loss: 0.5479 - accuracy: 0.6720 - f1_m: 0.5746 - precision_m: 0.7638 - recall_m: 0.4971\n",
      "Epoch 11/100\n",
      "125/125 [==============================] - 23s 180ms/step - loss: 0.5410 - accuracy: 0.6910 - f1_m: 0.6009 - precision_m: 0.7738 - recall_m: 0.5315\n",
      "Epoch 12/100\n",
      "125/125 [==============================] - 22s 174ms/step - loss: 0.5363 - accuracy: 0.6910 - f1_m: 0.6126 - precision_m: 0.7918 - recall_m: 0.5326\n",
      "Epoch 13/100\n",
      "125/125 [==============================] - 19s 152ms/step - loss: 0.5310 - accuracy: 0.6935 - f1_m: 0.6065 - precision_m: 0.7890 - recall_m: 0.5222\n",
      "Epoch 14/100\n",
      "125/125 [==============================] - 20s 161ms/step - loss: 0.5417 - accuracy: 0.6785 - f1_m: 0.6463 - precision_m: 0.7452 - recall_m: 0.6195\n",
      "Epoch 15/100\n",
      "125/125 [==============================] - 19s 151ms/step - loss: 0.5220 - accuracy: 0.7035 - f1_m: 0.6432 - precision_m: 0.7921 - recall_m: 0.5742\n",
      "Epoch 16/100\n",
      "125/125 [==============================] - 23s 187ms/step - loss: 0.5147 - accuracy: 0.7045 - f1_m: 0.6391 - precision_m: 0.7810 - recall_m: 0.5809\n",
      "Epoch 17/100\n",
      "125/125 [==============================] - 26s 204ms/step - loss: 0.5239 - accuracy: 0.7050 - f1_m: 0.6404 - precision_m: 0.7690 - recall_m: 0.5901\n",
      "Epoch 18/100\n",
      "125/125 [==============================] - 28s 227ms/step - loss: 0.5089 - accuracy: 0.7025 - f1_m: 0.6628 - precision_m: 0.7696 - recall_m: 0.6153\n",
      "Epoch 19/100\n",
      "125/125 [==============================] - 26s 206ms/step - loss: 0.5086 - accuracy: 0.7300 - f1_m: 0.6801 - precision_m: 0.7898 - recall_m: 0.6322\n",
      "Epoch 20/100\n",
      "125/125 [==============================] - 23s 183ms/step - loss: 0.5040 - accuracy: 0.7290 - f1_m: 0.6660 - precision_m: 0.8020 - recall_m: 0.6157\n",
      "Epoch 21/100\n",
      "125/125 [==============================] - 24s 195ms/step - loss: 0.4943 - accuracy: 0.7285 - f1_m: 0.6871 - precision_m: 0.7876 - recall_m: 0.6420\n",
      "Epoch 22/100\n",
      "125/125 [==============================] - 24s 195ms/step - loss: 0.4864 - accuracy: 0.7350 - f1_m: 0.6795 - precision_m: 0.7966 - recall_m: 0.6282\n",
      "Epoch 23/100\n",
      "125/125 [==============================] - 24s 194ms/step - loss: 0.4960 - accuracy: 0.7250 - f1_m: 0.6893 - precision_m: 0.7826 - recall_m: 0.6457\n",
      "Epoch 24/100\n",
      "125/125 [==============================] - 25s 197ms/step - loss: 0.4851 - accuracy: 0.7360 - f1_m: 0.7077 - precision_m: 0.7639 - recall_m: 0.6948\n",
      "Epoch 25/100\n",
      "125/125 [==============================] - 25s 196ms/step - loss: 0.4914 - accuracy: 0.7320 - f1_m: 0.6929 - precision_m: 0.7767 - recall_m: 0.6690\n",
      "Epoch 26/100\n",
      "125/125 [==============================] - 25s 196ms/step - loss: 0.4830 - accuracy: 0.7375 - f1_m: 0.6929 - precision_m: 0.7682 - recall_m: 0.6709\n",
      "Epoch 27/100\n",
      "125/125 [==============================] - 25s 196ms/step - loss: 0.4772 - accuracy: 0.7425 - f1_m: 0.7176 - precision_m: 0.7752 - recall_m: 0.7010\n",
      "Epoch 28/100\n",
      "125/125 [==============================] - 24s 192ms/step - loss: 0.4783 - accuracy: 0.7425 - f1_m: 0.7196 - precision_m: 0.7599 - recall_m: 0.7238\n",
      "Epoch 29/100\n",
      "125/125 [==============================] - 24s 195ms/step - loss: 0.4806 - accuracy: 0.7625 - f1_m: 0.7388 - precision_m: 0.7700 - recall_m: 0.7482\n",
      "Epoch 30/100\n",
      "125/125 [==============================] - 25s 202ms/step - loss: 0.4636 - accuracy: 0.7685 - f1_m: 0.7542 - precision_m: 0.7670 - recall_m: 0.7757\n",
      "Epoch 31/100\n",
      "125/125 [==============================] - 26s 209ms/step - loss: 0.4706 - accuracy: 0.7700 - f1_m: 0.7551 - precision_m: 0.7849 - recall_m: 0.7676\n",
      "Epoch 32/100\n",
      "125/125 [==============================] - 27s 213ms/step - loss: 0.4684 - accuracy: 0.7685 - f1_m: 0.7606 - precision_m: 0.7719 - recall_m: 0.7736\n",
      "Epoch 33/100\n",
      "125/125 [==============================] - 29s 231ms/step - loss: 0.4636 - accuracy: 0.7660 - f1_m: 0.7515 - precision_m: 0.7650 - recall_m: 0.7759\n",
      "Epoch 34/100\n",
      "125/125 [==============================] - 27s 219ms/step - loss: 0.4597 - accuracy: 0.7705 - f1_m: 0.7600 - precision_m: 0.7774 - recall_m: 0.7713\n",
      "Epoch 35/100\n",
      "125/125 [==============================] - 25s 203ms/step - loss: 0.4445 - accuracy: 0.7830 - f1_m: 0.7671 - precision_m: 0.7705 - recall_m: 0.8015\n",
      "Epoch 36/100\n",
      "125/125 [==============================] - 27s 215ms/step - loss: 0.4419 - accuracy: 0.7850 - f1_m: 0.7757 - precision_m: 0.7851 - recall_m: 0.7977\n",
      "Epoch 37/100\n",
      "125/125 [==============================] - 24s 193ms/step - loss: 0.4418 - accuracy: 0.7865 - f1_m: 0.7844 - precision_m: 0.7653 - recall_m: 0.8297\n",
      "Epoch 38/100\n",
      "125/125 [==============================] - 24s 195ms/step - loss: 0.4460 - accuracy: 0.7740 - f1_m: 0.7688 - precision_m: 0.7641 - recall_m: 0.8060\n",
      "Epoch 39/100\n",
      "125/125 [==============================] - 24s 194ms/step - loss: 0.4295 - accuracy: 0.7910 - f1_m: 0.7855 - precision_m: 0.7805 - recall_m: 0.8132\n",
      "Epoch 40/100\n",
      "125/125 [==============================] - 24s 192ms/step - loss: 0.4342 - accuracy: 0.7880 - f1_m: 0.7792 - precision_m: 0.7782 - recall_m: 0.8072\n",
      "Epoch 41/100\n",
      "125/125 [==============================] - 24s 194ms/step - loss: 0.4334 - accuracy: 0.7820 - f1_m: 0.7809 - precision_m: 0.7657 - recall_m: 0.8250\n",
      "Epoch 42/100\n",
      "125/125 [==============================] - 25s 196ms/step - loss: 0.4376 - accuracy: 0.7855 - f1_m: 0.7820 - precision_m: 0.7743 - recall_m: 0.8304\n",
      "Epoch 43/100\n",
      "125/125 [==============================] - 24s 194ms/step - loss: 0.4440 - accuracy: 0.7815 - f1_m: 0.7758 - precision_m: 0.7624 - recall_m: 0.8220\n",
      "Epoch 44/100\n",
      "125/125 [==============================] - 25s 199ms/step - loss: 0.4242 - accuracy: 0.7945 - f1_m: 0.7840 - precision_m: 0.7749 - recall_m: 0.8247\n",
      "Epoch 45/100\n",
      "125/125 [==============================] - 26s 208ms/step - loss: 0.4402 - accuracy: 0.7905 - f1_m: 0.7936 - precision_m: 0.7747 - recall_m: 0.8459\n",
      "Epoch 46/100\n",
      "125/125 [==============================] - 30s 243ms/step - loss: 0.4390 - accuracy: 0.7850 - f1_m: 0.7859 - precision_m: 0.7545 - recall_m: 0.8520\n",
      "Epoch 47/100\n",
      "125/125 [==============================] - 31s 245ms/step - loss: 0.4193 - accuracy: 0.8045 - f1_m: 0.8030 - precision_m: 0.7925 - recall_m: 0.8395\n",
      "Epoch 48/100\n",
      "125/125 [==============================] - 24s 188ms/step - loss: 0.4319 - accuracy: 0.7995 - f1_m: 0.8007 - precision_m: 0.7950 - recall_m: 0.8385\n",
      "Epoch 49/100\n",
      "125/125 [==============================] - 26s 209ms/step - loss: 0.4222 - accuracy: 0.7920 - f1_m: 0.7841 - precision_m: 0.7712 - recall_m: 0.8319\n",
      "Epoch 50/100\n",
      "125/125 [==============================] - 30s 239ms/step - loss: 0.4293 - accuracy: 0.7970 - f1_m: 0.7935 - precision_m: 0.7810 - recall_m: 0.8378\n",
      "Epoch 51/100\n",
      "125/125 [==============================] - 24s 193ms/step - loss: 0.4132 - accuracy: 0.8045 - f1_m: 0.8013 - precision_m: 0.7910 - recall_m: 0.8407\n",
      "Epoch 52/100\n",
      "125/125 [==============================] - 28s 220ms/step - loss: 0.4071 - accuracy: 0.8165 - f1_m: 0.8141 - precision_m: 0.7993 - recall_m: 0.8520\n",
      "Epoch 53/100\n",
      "125/125 [==============================] - 26s 204ms/step - loss: 0.4131 - accuracy: 0.8035 - f1_m: 0.8041 - precision_m: 0.7979 - recall_m: 0.8391\n",
      "Epoch 54/100\n",
      "125/125 [==============================] - 26s 209ms/step - loss: 0.4183 - accuracy: 0.8060 - f1_m: 0.8042 - precision_m: 0.7977 - recall_m: 0.8467\n",
      "Epoch 55/100\n",
      "125/125 [==============================] - 24s 191ms/step - loss: 0.4130 - accuracy: 0.7925 - f1_m: 0.7922 - precision_m: 0.7729 - recall_m: 0.8433\n",
      "Epoch 56/100\n",
      "125/125 [==============================] - 26s 205ms/step - loss: 0.3994 - accuracy: 0.8140 - f1_m: 0.8103 - precision_m: 0.8018 - recall_m: 0.8498\n",
      "Epoch 57/100\n",
      "125/125 [==============================] - 25s 199ms/step - loss: 0.4047 - accuracy: 0.8095 - f1_m: 0.8046 - precision_m: 0.7853 - recall_m: 0.8507\n",
      "Epoch 58/100\n",
      "125/125 [==============================] - 26s 209ms/step - loss: 0.3897 - accuracy: 0.8175 - f1_m: 0.8094 - precision_m: 0.8078 - recall_m: 0.8435\n",
      "Epoch 59/100\n",
      "125/125 [==============================] - 21s 170ms/step - loss: 0.4109 - accuracy: 0.8045 - f1_m: 0.8035 - precision_m: 0.7781 - recall_m: 0.8582\n",
      "Epoch 60/100\n",
      "125/125 [==============================] - 19s 154ms/step - loss: 0.4067 - accuracy: 0.8070 - f1_m: 0.8064 - precision_m: 0.7868 - recall_m: 0.8584\n",
      "Epoch 61/100\n",
      "125/125 [==============================] - 19s 150ms/step - loss: 0.3945 - accuracy: 0.8155 - f1_m: 0.8098 - precision_m: 0.7996 - recall_m: 0.8486\n",
      "Epoch 62/100\n",
      "125/125 [==============================] - 19s 148ms/step - loss: 0.4036 - accuracy: 0.8105 - f1_m: 0.8064 - precision_m: 0.7821 - recall_m: 0.8577\n",
      "Epoch 63/100\n",
      "125/125 [==============================] - 19s 152ms/step - loss: 0.3884 - accuracy: 0.8140 - f1_m: 0.8194 - precision_m: 0.8028 - recall_m: 0.8588\n",
      "Epoch 64/100\n",
      "125/125 [==============================] - 19s 153ms/step - loss: 0.3826 - accuracy: 0.8265 - f1_m: 0.8180 - precision_m: 0.8060 - recall_m: 0.8601\n",
      "Epoch 65/100\n",
      "125/125 [==============================] - 19s 150ms/step - loss: 0.3978 - accuracy: 0.8155 - f1_m: 0.8179 - precision_m: 0.8002 - recall_m: 0.8661\n",
      "Epoch 66/100\n",
      "125/125 [==============================] - 19s 150ms/step - loss: 0.3801 - accuracy: 0.8210 - f1_m: 0.8162 - precision_m: 0.8028 - recall_m: 0.8551\n",
      "Epoch 67/100\n",
      "125/125 [==============================] - 20s 156ms/step - loss: 0.3968 - accuracy: 0.8200 - f1_m: 0.8128 - precision_m: 0.8018 - recall_m: 0.8504\n",
      "Epoch 68/100\n",
      "125/125 [==============================] - 19s 154ms/step - loss: 0.3733 - accuracy: 0.8240 - f1_m: 0.8227 - precision_m: 0.8061 - recall_m: 0.8639\n",
      "Epoch 69/100\n",
      "125/125 [==============================] - 20s 157ms/step - loss: 0.3879 - accuracy: 0.8140 - f1_m: 0.8137 - precision_m: 0.7981 - recall_m: 0.8523\n",
      "Epoch 70/100\n",
      "125/125 [==============================] - 18s 143ms/step - loss: 0.3723 - accuracy: 0.8240 - f1_m: 0.8232 - precision_m: 0.7994 - recall_m: 0.8733\n",
      "Epoch 71/100\n",
      "125/125 [==============================] - 18s 146ms/step - loss: 0.3928 - accuracy: 0.8185 - f1_m: 0.8152 - precision_m: 0.7959 - recall_m: 0.8657\n",
      "Epoch 72/100\n",
      "125/125 [==============================] - 19s 149ms/step - loss: 0.3706 - accuracy: 0.8365 - f1_m: 0.8368 - precision_m: 0.8115 - recall_m: 0.8885\n",
      "Epoch 73/100\n",
      "125/125 [==============================] - 19s 150ms/step - loss: 0.3733 - accuracy: 0.8250 - f1_m: 0.8197 - precision_m: 0.8042 - recall_m: 0.8670\n",
      "Epoch 74/100\n",
      "125/125 [==============================] - 19s 152ms/step - loss: 0.3660 - accuracy: 0.8325 - f1_m: 0.8373 - precision_m: 0.8098 - recall_m: 0.8883\n",
      "Epoch 75/100\n",
      "125/125 [==============================] - 19s 151ms/step - loss: 0.3752 - accuracy: 0.8270 - f1_m: 0.8240 - precision_m: 0.8025 - recall_m: 0.8687\n",
      "Epoch 76/100\n",
      "125/125 [==============================] - 20s 160ms/step - loss: 0.3767 - accuracy: 0.8270 - f1_m: 0.8265 - precision_m: 0.8079 - recall_m: 0.8686\n",
      "Epoch 77/100\n",
      "125/125 [==============================] - 20s 162ms/step - loss: 0.3757 - accuracy: 0.8220 - f1_m: 0.8249 - precision_m: 0.8026 - recall_m: 0.8712\n",
      "Epoch 78/100\n",
      "125/125 [==============================] - 20s 163ms/step - loss: 0.3660 - accuracy: 0.8315 - f1_m: 0.8277 - precision_m: 0.8086 - recall_m: 0.8720\n",
      "Epoch 79/100\n",
      "125/125 [==============================] - 19s 148ms/step - loss: 0.3678 - accuracy: 0.8340 - f1_m: 0.8271 - precision_m: 0.8160 - recall_m: 0.8684\n",
      "Epoch 79: early stopping\n"
     ]
    }
   ],
   "source": [
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    callbacks=[callback],\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples // batch_size)\n",
    "\n",
    "model.save_weights('first_try.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 37ms/step - loss: 1.4079 - accuracy: 0.4750 - f1_m: 0.5015 - precision_m: 0.4664 - recall_m: 0.5680\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy, f1_score, precision, recall = model.evaluate(test_generator)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7440110c6c0182a2dad1e703c372f102fad2eda689aaa35569e8dc8df298813"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
